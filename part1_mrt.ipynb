{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "part1_mrt.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNfhBL74egPa9IwOrBJvOQi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wdempsey/AI4Health-Online-Experimentation/blob/main/part1_mrt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRMH8jI_13OX"
      },
      "source": [
        "# Online learning and experimentation algorithms in mobile health\r\n",
        "\r\n",
        "In part 1, we will discuss the _micro-randomized trial design_ and the corresponding primary data analysis methods.  By the end of this section, you should be able to answer the following set of questions:\r\n",
        "- What is a just-in-time adaptive intervention (JITAI)? \r\n",
        "- What is a micro-randomized trial?\r\n",
        "- What is causal excursion effect?  How does one estimate this effect?\r\n",
        "- What are the  goals of early-stage optimization trials?\r\n",
        "\r\n",
        "In addition, we will introduce the _HeartSteps simulator_.  This is a set of functions which allows us to generate synthetic users in a mock MRT.  We will use this simulator in additional sections as well. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvhbY9u0mwXb"
      },
      "source": [
        "## Import necessary \n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YKIaRcmwv-g"
      },
      "source": [
        "# Part 1: Just-in-time adaptive interventions\r\n",
        "\r\n",
        "A JITAI is ``is an intervention design aiming to provide the right type/amount of support, at the right time, by adapting to an individual's changing internal and contextual state'' (Nahum-Shani, 2018).  \r\n",
        "\r\n",
        "- The term “just-in-time support” is used to describe an attempt to provide the right type (or amount) of support, at the right time.\r\n",
        "- Timing is largely event-based, e.g., \"a moment of high vulnerability and high receptivity\".  \r\n",
        "  - Ex. For a person attempting to quit smoking, a moment of high stress may lead to high likelihood of relapse.  If the person is currently available (e.g., no meeting on Google Calendar) and not currently active (e.g., not out for a walk), then the person may be receptive to a brief prompt aimed at reducing proximal stress.\r\n",
        "- __Decision Points__: A decision point is a time at which an intervention decision is made. \r\n",
        "- __Intervention Options__: An array of possible treatments or actions that might be employed at any given decision point.\r\n",
        "  - Ex. Options are ``Send Message`` or ``Do Nothing``\r\n",
        "- __Tailoring Variable__: A tailoring variable is information concerning the individual that is used to decide when (i.e., under what conditions) to provide an intervention and which intervention to provide. \r\n",
        "  - Ex. An individual's distance from a high-risk location (A-CHESS)\r\n",
        "- __Outcome__:\r\n",
        "  - __Distal outcome__: Ultimate goal the intervention is intended to achieve; it is usually a primary clinical outcome, such as weight loss, drug/alcohol use reduction or increase in average activity level.  \r\n",
        "  - __Proximal outcome__: Short-term goals the intervention options are intended to achieve.  Typically thought to be on the causal pathway (i.e., a mediator).\r\n",
        "- __Decision rules__:  Operationalize the adaptation by specifying which intervention option to offer, for whom, and when. \r\n",
        "  - Ex. __``If``__ ``At High Risk Location``, __``Then``__ ``IO = Send Message``, __``Else``__ ``IO = Do Nothing``.\r\n",
        "\r\n",
        "A JITAI is an _intervention design_.  Behavioral scientists often have questions in how to best design a JITAI for a particular behavioral health setting.  Consider an mHealth smoking cessation setting.  Scientists may wish to intervene by either sending a reminder to practice mindfulness (hopefully reducing proximal stress) or not; however, it is unknown whether sending the message when the individual is currently stressed (high vulnerability but low receptivity) is better than when the individual is current not stressed (low vulnerability but high receptivity).  \r\n",
        "\r\n",
        "- __Group Task 1__: Construct a JITAI to be included in a smoking cessation mHealth intervention package based on the above.  Be sure to highlight the 5 key elements.   \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6qWBt8x2BEW"
      },
      "source": [
        "#Part 2: Micro-randomized trials (MRTs)\n",
        "\n",
        "MRTs are an experimental design to collect data to answer questions about the construction of JITAIs. \n",
        "\n",
        "- For each person in a study, let $t=1,\\ldots, T$ denote a sequence of decision points.  \n",
        "- At each decision time $t$,  we observe a state variable $S_t \\in \\mathbb{R}^p$.  \n",
        "- After observing the state variable $S_t$, the _clinical trialist_ decides to take action $A_t \\in \\mathcal{A}$ with probability $p_t (A_t \\mid H_t)$ (i.e., the randomization probability may depend on the observed history $H_t$).  \n",
        "- After observing state $S_t$ and taking action $A_t$, the agent observes the proximal response $Y_{t+1}$.  The proximal response is a deterministic function of state, action, and next state (i.e., $Y_{t+1} = g(S_t, A_t, S_{t+1})$)\n",
        "- The sequence of state, action, and reward at a sequence of decision points defines a _micro-randomized trial_, $\\{ S_t, A_t, Y_{t+1} \\}_{t=1}^T$.\n",
        "- Here, our goal is to collect data to optimize an intervention component\n",
        "  - Q1: Should we include this intervention component in an overall intervention package?\n",
        "  - Q2: What should the decision rule be in the optimized JITAI?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVoo7_phPz6J"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIRfY7By1qUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5986b723-7b42-4cee-f863-c9ac0922000e"
      },
      "source": [
        "# Simulation example\n",
        "T = 200 # number of steps\n",
        "\n",
        "## Generate context (normal and binary states)\n",
        "mu, sigma = 0, 1 # mean and standard deviation\n",
        "state1 = np.random.normal(mu, sigma, T) # Continuous state\n",
        "state2 = np.random.binomial(n=1, p = 0.7,size=T) # Binary state\n",
        "state = np.stack((state1,state2), axis = 1) # Compelte State at each time\n",
        "\n",
        "## Generate actions (MRT with probability  )\n",
        "action = np.random.binomial(n=1, p = 0.6,size=T) # Binary state\n",
        "\n",
        "## Generate true reward\n",
        "def proximaloutcome(state, action):\n",
        "  base_reward = state[0] + 0.3*state[1] \n",
        "  advantage = 0.5*state[0] - 0.7*state[1]\n",
        "  return base_reward + advantage * (action - 0.6)\n",
        "\n",
        "y = np.repeat(0.,T)\n",
        "for t in range(T):\n",
        "  y[t] = reward(state[t,:], action[t]) + np.random.normal(0, 1, 1)\n",
        "\n",
        "\n",
        "## Triple\n",
        "triple = np.column_stack((state,action, y))\n",
        "print(\"First 10 entries of state (2D), action, and reward\")\n",
        "print(triple[1:10,:])\n",
        "print(\"\\n\")\n",
        "\n",
        "## Build the design matrix\n",
        "X = state\n",
        "for col in range(2):\n",
        "  temp = np.multiply(state[:,col],action)\n",
        "  X = np.column_stack((X, temp))\n",
        "\n",
        "reg = LinearRegression().fit(X,y)\n",
        "print(\"True coefficients using linear model\")\n",
        "print(np.array([1,0.3,0.5,-0.7]))\n",
        "print(\"Fitted coefficients using linear model\")\n",
        "print(reg.coef_)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First 10 entries of state (2D), action, and reward\n",
            "[[ 0.4889732   0.          0.          0.0970272 ]\n",
            " [-1.65526392  1.          0.         -2.15776888]\n",
            " [ 0.88552154  0.          0.          1.29955221]\n",
            " [-1.21393632  1.          0.          0.97508805]\n",
            " [-1.79251348  1.          0.         -1.62145004]\n",
            " [ 1.42910115  0.          1.          1.68040017]\n",
            " [-2.05180643  1.          0.         -3.29626183]\n",
            " [ 0.2045409   1.          0.          1.70142421]\n",
            " [ 2.92629192  1.          0.          1.87006771]]\n",
            "\n",
            "\n",
            "True coefficients using linear model\n",
            "[ 1.   0.3  0.5 -0.7]\n",
            "Fitted coefficients using linear model\n",
            "[ 1.08134331  0.49970343  0.50450428 -0.64743794]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwolFIRmvIqC"
      },
      "source": [
        "## Question 1: How can we adapt the traditional RCT estimand to the current setting?\r\n",
        "\r\n",
        "In an RCT, the __average treatment effect__ (ATE) is of interest.  This is defined as\r\n",
        "$$\r\n",
        "\\mathbb{E} \\left[ Y(1) - Y(0) \\right] \r\n",
        "$$\r\n",
        "where $Y(1)$ and $Y(0)$ are the potential outcomes for the participant under treatment $(z=1)$ and control $(z=0)$ respectively.  The expectation is with respect to the population.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYJQPaKw8Ash"
      },
      "source": [
        "- The only thing that impacts decision to choose $a = 1$ or $a=0$ is the _advantage function_:\n",
        "$$\n",
        "A(s) = r(s,1) - r(s,0)\n",
        "$$\n",
        "- In the example above\n",
        "$$\n",
        "A(s) = 0.5 s_{0} - 0.7 s_{1} > 0 \\Rightarrow \\frac{0.5}{0.7} s_0 > s_1\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbnRinwV8DSb"
      },
      "source": [
        "## Question 2: What goes into choosing the randomization probabilities?\n",
        "\n",
        "- Why may we not want to use a simple Bernoulli $p=1/2$ coin flip to collect data in all micro-randomized trials?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfrZnOLpMKQI"
      },
      "source": [
        "Some reasons include\n",
        "  - __Burden__: users may not tolerate receiving many messages per day.  Suppose there were 5 decision points per day.  In an mHealth study aimed at increasing physical activity, too many messages sent on average may over-burden users?  How do we find out this dosage?\n",
        "  - __Availability__:  sometimes it may not be possible due to ethical or feasibility issues to provide treatment.  \n",
        "  - __At-risk times__: it may only be useful to provide interventions in certain states.  In Sense2Stop, a smoking cessation may only want to provide \n",
        "  - __Prior data__: \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gejXfi7AvMYD"
      },
      "source": [
        "# Part 2b: Running a synthetic MRT\n",
        "\n",
        "The ``HeartSteps simulator`` is built upon HeartSteps V2, decision points are 6 times per day.  \n",
        "Variables include\n",
        "- __ID (string)__ is a unique identifier for the decision\n",
        "Heartsteps ID (string) is the ID for the participant in the study\n",
        "Test (boolean) is if the walking suggestion was a test explicitly sent to the participant, and shouldn’t be included in analysis\n",
        "- __Decision time (datetime string YYYY-MM-DD HH:MM:SS)__ is the time the decision to treat or not treat the participant was made. This time might be slightly different than the time the participant was sent or received the walking suggestion push notification. The time of day is reported in a 24 hour format and is localized to the participant’s timezone at the decision time.\n",
        "Sedentary (boolean) if the participant is sedentary, it means HeartSteps had recorded less than 250 steps in the last 60 minutes.\n",
        "- __Treated (boolean)__ indicates that the participant was randomized to receive a walking suggestion at the time of the walking suggestion decision. This value is typically generated by the walking-suggestion-service.\n",
        "- __Treatment Probability (decimal between 0 and 1)__ this is the probability that the participant would be sent a walking suggestion. 1 means the participant will be sent a walking suggestion, 0 means the participant will not be sent a walking suggestion. If Available is false, then the treatment probability should be zero. This value is typically generated by the walking-suggestion-service.\n",
        "- __Notification Title (string)__ is the title of the push notification sent to the participant. If this field is missing, then a walking suggestion wasn’t sent to the participant.\n",
        "- __Notification Message (string)__ is the message that was sent to the participant. If this field is missing, then a walking suggestion wasn’t sent.\n",
        "Sent Time (datetime string YYYY-MM-DD HH:MM:SS) is the time that the walking suggestion decision was sent to the participant, which can be slightly different than the time the participant received the message. Hours are reported using a 24 hour clock, the timezone for this message is the participant’s current timezone. If this value is missing, it means the participant was randomized to not receive a message, or the decision was imputed (see below).\n",
        "- __Engaged Time (datetime string YYYY-MM-DD HH:MM:SS)__ is when the participant clicked “Ok” at the bottom of the walking suggestion in the heartsteps-app. Hours are reported using a 24 hour clock, the timezone for this message is the participant’s current timezone. This value will be missing if the participant opened the push notification, but closed the heartsteps-app before clicking “Ok” -- this value could also be missing for the same reasons as sent time.\n",
        "- __Location (string)__ is the participant’s location represented as a category at the walking suggestion decision time. The category is determined by comparing the participant’s last GPS location reported by the heartsteps-clock-face, to the list of places the participant entered during the onboarding process -- if the participant is within 500 meters of a defined place, they are determined to be at that place. Possible values are “home” “work” or “other”. It’s possible for this field to be empty, which indicates that we haven’t received a location record from the participant within the last 60 minutes.\n",
        "- __Temperature (integer)__ the temperature in fahrenheit for the participant’s location at the walking suggestion decision time as reported by the DarkSky API. If there is no reported location for the walking suggestion decision, then the temperature reported is the average temperature for each place the participant defined in the onboarding process.\n",
        "- __Precipitation Type (string)__ is the type of precipitation reported by the DarkSky API for the participant’s current location. Possible values are “None” “Rain” and “Snow”. If the participant’s location is missing at the walking suggestion time, this value represents the most extreme value from each place the participant defined during onboarding (eg Snow is more extreme than Rain, which is more extreme than None).\n",
        "- __Precipitation Probability (decimal between 0 and 1)__ is the probability of precipitation reported by the DarkSky API for the participant’s current location. If the participant’s location is missing, then this value is the average precipitation probability at each place that a participant defined during onboarding.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLnC-1K2cJRg"
      },
      "source": [
        "## Reading in the data\n",
        "\n",
        "\n",
        "## ADD CODE FOR EXPLORATORY DATA ANALYSIS HERE\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDCeGJpT3WhL"
      },
      "source": [
        "# Part 3a: Causal Excursion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qrftxRRALno"
      },
      "source": [
        "# Part 3a: Primary analysis method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG7DWkq2APRo"
      },
      "source": [
        "# Part 3b: "
      ]
    }
  ]
}